{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lua es Torch alapok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tenzorok létrehozása, memóriakezelés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'torch';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x=torch.Tensor(7,5,6,2) -- 7x5x6x2-es tenzor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4\t\n",
       " 7\n",
       " 5\n",
       " 6\n",
       " 2\n",
       "[torch.LongStorage of size 4]\n",
       "\n",
       " 7\n",
       " 5\n",
       " 6\n",
       " 2\n",
       "[torch.LongStorage of size 4]\n",
       "\n",
       "7\t\n",
       "420\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x:dim())      -- az x tomb dimenzioinak szama\n",
    "print(#x)           -- az x tomb merete (elemszam az egyes dimenziok menten)\n",
    "print(x:size())     -- igy is lehet\n",
    "print(x:size(1))    -- az elso dimenzio merete\n",
    "print(x:nElement()) -- osszes elem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  4\n",
       "  7\n",
       "  2\n",
       " 11\n",
       "  3\n",
       "  1\n",
       "[torch.LongStorage of size 6]\n",
       "\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- 4-nel tobb dimenzios tombot az alabbi modon hozhatunk letre:\n",
    "s=torch.LongStorage(6)\n",
    "s[1]=4; s[2]=7; s[3]=2; s[4]=11; s[5]=3; s[6]=1;\n",
    "x=torch.Tensor(s) -- 4x7x2x11x3x1-es tomb\n",
    "print(#x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  1   2   3   4   5\n",
       "  6   7   8   9  10\n",
       " 11  12  13  14  15\n",
       " 16  17  18  19  20\n",
       "[torch.DoubleTensor of size 4x5]\n",
       "\n",
       "  1\n",
       "  2\n",
       "  3\n",
       "  4\n",
       "  5\n",
       "  6\n",
       "  7\n",
       "  8\n",
       "  9\n",
       " 10\n",
       " 11\n",
       " 12\n",
       " 13\n",
       " 14\n",
       " 15\n",
       " 16\n",
       " 17\n",
       " 18\n",
       " 19\n",
       " 20\n",
       "[torch.DoubleStorage of size 20]\n",
       "\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.Tensor(4,5) -- 4x5-os matrix\n",
    "s=x:storage() -- memoriakep\n",
    "for i=1,s:size() do\n",
    "    s[i]=i\n",
    "end\n",
    "print(x) -- a storage-et irtuk, de a tenzor is modosult!\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 10  11  12  13  14\n",
       " 15  16  17  18  19\n",
       " 20  21  22  23  24\n",
       " 25  26  27  28  29\n",
       "[torch.DoubleTensor of size 4x5]\n",
       "\n",
       " 10\n",
       " 11\n",
       " 12\n",
       " 13\n",
       " 14\n",
       " 15\n",
       " 16\n",
       " 17\n",
       " 18\n",
       " 19\n",
       " 20\n",
       " 21\n",
       " 22\n",
       " 23\n",
       " 24\n",
       " 25\n",
       " 26\n",
       " 27\n",
       " 28\n",
       " 29\n",
       "[torch.DoubleStorage of size 20]\n",
       "\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k=10\n",
    "for i=1,x:size(1) do\n",
    "    for j=1,x:size(2) do\n",
    "        x[i][j]=k\n",
    "        k=k+1\n",
    "    end\n",
    "end\n",
    "print(x)\n",
    "print(s) -- forditva: most a tombot irtuk, de a storage is modosult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 10  11  12  13  14\n",
       " 15  16  17  18  19\n",
       " 20  21  22  23  24\n",
       " 25  26  27  28   0\n",
       "[torch.DoubleTensor of size 4x5]\n",
       "\n",
       " 10  11  12  13  14\n",
       " 15  16  17  18  19\n",
       " 20  21  22  23  24\n",
       " 25  26  27  28   0\n",
       "[torch.DoubleTensor of size 4x5]\n",
       "\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=torch.Tensor(x) -- ugyanaz a storage, shallow copy!\n",
    "y[4][5]=0\n",
    "print(y)\n",
    "print(x) -- x is modosult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0  11  12  13  14  15  16  17  18  19\n",
       " 20  21  22  23  24  25  26  27  28   0\n",
       "[torch.DoubleTensor of size 2x10]\n",
       "\n",
       " 10  11  12  13  14\n",
       " 15  16  17  18  19\n",
       " 20  21  22  23  24\n",
       " 25  26  27  28   0\n",
       "[torch.DoubleTensor of size 4x5]\n",
       "\n",
       "  0  11  12  13\n",
       " 14  15  16  17\n",
       " 18  19  20  21\n",
       " 22  23  24  25\n",
       " 26  27  28   0\n",
       "[torch.DoubleTensor of size 5x4]\n",
       "\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z=torch.Tensor(2,10):copy(x) -- deep copy mas merettel\n",
    "z[1][1]=0\n",
    "print(z)\n",
    "print(x) -- nem modosult\n",
    "print(z:view(5,4)) -- mint a NumPy view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 10  11  12  13  14\n",
       " 15  16  17  18  19\n",
       " 20  21  22  23  24\n",
       " 25  26  27  28   0\n",
       "[torch.DoubleTensor of size 4x5]\n",
       "\n",
       " 1000    11    12    13    14\n",
       "   15    16    17    18    19\n",
       "   20    21    22    23    24\n",
       "   25    26    27    28     0\n",
       "[torch.DoubleTensor of size 4x5]\n",
       "\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_clone=x:clone() -- ez is deep copy\n",
    "x_clone[1][1]=1000\n",
    "print(x)\n",
    "print(x_clone) -- most csak a masolat modosult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 3.1400  3.1400  3.1400  3.1400  3.1400\n",
       " 3.1400  3.1400  3.1400  3.1400  3.1400\n",
       " 3.1400  3.1400  3.1400  3.1400  3.1400\n",
       " 3.1400  3.1400  3.1400  3.1400  3.1400\n",
       "[torch.DoubleTensor of size 4x5]\n",
       "\n",
       " 55  55  55  55  55\n",
       " 55  55  55  55  55\n",
       "[torch.DoubleTensor of size 2x5]\n",
       "\n",
       " 0  0  0  0  0\n",
       " 0  0  0  0  0\n",
       "[torch.DoubleTensor of size 2x5]\n",
       "\n",
       " 1  2  3  4\n",
       " 5  6  7  8\n",
       "[torch.DoubleTensor of size 2x4]\n",
       "\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x:fill(3.14) -- a tomb feltoltese\n",
    "print(x)\n",
    "x=torch.Tensor(2,5):fill(55) -- letrehozaskor is lehet\n",
    "print(x)\n",
    "x:zero() -- kinullazas\n",
    "print(x)\n",
    "x=torch.Tensor({{1,2,3,4},{5,6,7,8}}) -- elemek felsorolasaval is letrehozhatjuk\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.DoubleTensor\t\n",
       " 1.0000  2.0000  3.0000  4.0000\n",
       " 5.0000  6.0000  7.0000  8.2500\n",
       "[torch.DoubleTensor of size 2x4]\n",
       "\n",
       " 1  2  3  4\n",
       " 5  6  7  8\n",
       "[torch.IntTensor of size 2x4]\n",
       "\n",
       " 1.0000  2.0000  3.0000  4.0000\n",
       " 5.0000  6.0000  7.0000  8.2500\n",
       "[torch.FloatTensor of size 2x4]\n",
       "\n",
       " 1  2  3  4\n",
       " 5  6  7  8\n",
       "[torch.FloatTensor of size 2x4]\n",
       "\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[2][4]=8.25\n",
    "print(x:type())  -- addatipus\n",
    "print(x)\n",
    "print(x:int())   -- konvertalas egessze\n",
    "print(x:float()) -- es vissza lebegopontossa\n",
    "y=x:int()\n",
    "print(y:float()) -- termeszetesen igy elveszett a kerekitesi hiba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Függvények"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.8415  0.9093  0.1411 -0.7568\n",
       "-0.9589 -0.2794  0.6570  0.9226\n",
       "[torch.DoubleTensor of size 2x4]\n",
       "\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x:apply(math.sin) -- beepitett fuggveny hivasa x osszes elemere\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1  2  3\n",
       " 4  5  6\n",
       " 7  8  9\n",
       "[torch.DoubleTensor of size 3x3]\n",
       "\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.Tensor(3,3)\n",
    "i=0\n",
    "function fillMyTensor() -- elnevezett fuggveny\n",
    "    i=i+1\n",
    "    return i\n",
    "end\n",
    "x:apply(fillMyTensor) -- fuggveny alkalmazasa x minden elemere\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1  2  3\n",
       " 4  5  6\n",
       " 7  8  9\n",
       "[torch.DoubleTensor of size 3x3]\n",
       "\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.Tensor(3,3)\n",
    "i=0\n",
    "x:apply(function() i=i+1; return i end) -- nev nelkuli fuggveny (~ Python lambda)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  3   6   9\n",
       " 12  15  18\n",
       " 21  24  27\n",
       "[torch.DoubleTensor of size 3x3]\n",
       "\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function triple(k) -- parameteres fuggveny\n",
    "    return 3*k\n",
    "end\n",
    "x:apply(triple)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexelés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15\t\n",
       "15\t\n",
       " 12\n",
       " 15\n",
       " 18\n",
       "[torch.DoubleTensor of size 3]\n",
       "\n",
       "  6\n",
       " 15\n",
       " 24\n",
       "[torch.DoubleTensor of size 3]\n",
       "\n",
       "  6   9\n",
       " 15  18\n",
       "[torch.DoubleTensor of size 2x2]\n",
       "\n",
       "  3  12  21\n",
       "  6  15  24\n",
       "  9  18  27\n",
       "[torch.DoubleTensor of size 3x3]\n",
       "\n",
       "  3  12  21\n",
       "  6  15  24\n",
       "  9  18  27\n",
       "[torch.DoubleTensor of size 3x3]\n",
       "\n",
       "135\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x[2][2])          -- egy elem kivalasztasa (a Lua 1-tol indexel!)\n",
    "print(x[{2,2}])         -- igy is lehet\n",
    "print(x[2])             -- masodik sor kivalasztasa\n",
    "print(x[{{},2}])        -- masodik oszlop kivalasztasa\n",
    "print(x[{{1,2},{2,3}}]) -- almatrix kivalasztasa\n",
    "print(x:t())            -- transzponalt\n",
    "print(x:transpose(1,2)) -- igy is lehet\n",
    "print(x:sum())          -- elemek osszege"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       "[torch.DoubleTensor of size 5x6]\n",
       "\n",
       " 1  1  1  1  1  1\n",
       " 1  1  1  1  1  1\n",
       "[torch.DoubleTensor of size 2x6]\n",
       "\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 1  1  1  1  1  1\n",
       " 1  1  1  1  1  1\n",
       " 0  0  0  0  0  0\n",
       "[torch.DoubleTensor of size 5x6]\n",
       "\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.Tensor(5,6):zero()\n",
    "print(x)\n",
    "y=x:narrow(1,3,2) -- 1. dimenzio (sorok) menten a 3.-tol kezdve 2 elem kivalasztasa\n",
    "y:fill(1)\n",
    "print(y)\n",
    "print(x) -- ugyanaz a storage, x is valtozott!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0  0  8  0  0  0\n",
       " 0  0  8  0  0  0\n",
       " 1  1  8  1  1  1\n",
       " 1  1  8  1  1  1\n",
       " 0  0  8  0  0  0\n",
       "[torch.DoubleTensor of size 5x6]\n",
       "\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x:select(2,3):fill(8) -- 2. dimenzio (oszlopok) menten a harmadik elem kivalasztasa\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU támogatás"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vegrehajtasi ido: 6 s\t\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- idomeres\n",
    "A=torch.rand(500,500)\n",
    "B=torch.rand(500,500)\n",
    "t_start=os.time() -- masodperc merese\n",
    "for i=1,200 do\n",
    "    C=A*B -- 500x500-as matrixok szorzasa 200-szor\n",
    "end\n",
    "elapsed=os.difftime(os.time(),t_start)\n",
    "print(\"Vegrehajtasi ido: %d s\" % elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "--[[ ugyanez GPU tamogatassal\n",
    "\n",
    "require 'cutorch'\n",
    "A=torch.rand(500,500):cuda()\n",
    "B=torch.rand(500,500):cuda()\n",
    "t_start=os.time()\n",
    "for i=1,200 do\n",
    "    C=A*B\n",
    "end\n",
    "elapsed=os.difftime(os.time(),t_start)\n",
    "print(\"Vegrehajtasi ido: %d s\" % elapsed)\n",
    "\n",
    "]]--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
