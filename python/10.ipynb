{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kézzel írott számjegyek felismerése"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import struct\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST adatbázis betöltése"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tanito bemenetek beolvasasa\n",
    "f=open(\"mnist_database/train_60k_images.dat\",\"rb\")\n",
    "signature,=struct.unpack(\">I\",f.read(4))\n",
    "numimages,=struct.unpack(\">I\",f.read(4))\n",
    "rows,=struct.unpack(\">I\",f.read(4))\n",
    "cols,=struct.unpack(\">I\",f.read(4))\n",
    "if (rows!=28) or (cols!=28) or (signature!=2051) or (numimages!=60000):\n",
    "    print(\"Hiba!\")\n",
    "else:\n",
    "    train_images=np.empty([60000,784],dtype=\"float32\")\n",
    "    for i in range(60000):\n",
    "        train_images[i]=np.array(struct.unpack(\"784B\",f.read(784)),dtype=\"float32\")/255\n",
    "f.close()\n",
    "\n",
    "# tanito kimenetek beolvasasa\n",
    "f=open(\"mnist_database/train_60k_labels.dat\",\"rb\")\n",
    "fdata=f.read()\n",
    "f.close()\n",
    "signature,=struct.unpack(\">I\",fdata[0:4])\n",
    "numlabels,=struct.unpack(\">I\",fdata[4:8])\n",
    "if (signature!=2049) or (numlabels!=60000):\n",
    "    print(\"Hiba!\")\n",
    "else:\n",
    "    train_labels=np.zeros([60000,10])\n",
    "    for i in range(60000):\n",
    "        temp,=struct.unpack(\"B\",fdata[8+i])\n",
    "        train_labels[i][temp]=1\n",
    "fdata=[]\n",
    "\n",
    "# teszt bemenetek beolvasasa\n",
    "f=open(\"mnist_database/test_10k_images.dat\",\"rb\")\n",
    "signature,=struct.unpack(\">I\",f.read(4))\n",
    "numimages,=struct.unpack(\">I\",f.read(4))\n",
    "rows,=struct.unpack(\">I\",f.read(4))\n",
    "cols,=struct.unpack(\">I\",f.read(4))\n",
    "if (rows!=28) or (cols!=28) or (signature!=2051) or (numimages!=10000):\n",
    "    print(\"Hiba!\")\n",
    "else:\n",
    "    test_images=np.empty([10000,784],dtype=\"float32\")\n",
    "    for i in range(10000):\n",
    "        test_images[i]=np.array(struct.unpack(\"784B\",f.read(784)),dtype=\"float32\")/255\n",
    "f.close()\n",
    "\n",
    "# teszt kimenetek beolvasasa\n",
    "f=open(\"mnist_database/test_10k_labels.dat\",\"rb\")\n",
    "fdata=f.read()\n",
    "f.close()\n",
    "signature,=struct.unpack(\">I\",fdata[0:4])\n",
    "numlabels,=struct.unpack(\">I\",fdata[4:8])\n",
    "if (signature!=2049) or (numlabels!=10000):\n",
    "    print(\"Hiba!\")\n",
    "else:\n",
    "    test_labels=np.zeros([10000,10])\n",
    "    for i in range(10000):\n",
    "        temp,=struct.unpack(\"B\",fdata[8+i])\n",
    "        test_labels[i][temp]=1\n",
    "fdata=[]\n",
    "\n",
    "gc.collect()\n",
    "print(\"MNIST adatbazis betoltve.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Osztályozás egyszerű regresszióval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# batch_size darab, veletlenszeruen valasztott elemet ad vissza a tanito adatokbol\n",
    "def get_batch(batch_size):\n",
    "    global train_images, train_labels\n",
    "    perm=np.random.permutation(train_images.shape[0])\n",
    "    perm=perm[:batch_size]\n",
    "    return [train_images[perm,:],train_labels[perm,:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess=tf.Session()\n",
    "# bemenet es kimenet\n",
    "x =tf.placeholder(tf.float32,shape=[None,train_images.shape[1]])\n",
    "y_=tf.placeholder(tf.float32,shape=[None,train_labels.shape[1]])\n",
    "# sulymatrix es biasvektor\n",
    "W=tf.Variable(tf.zeros([train_images.shape[1],train_labels.shape[1]]))\n",
    "b=tf.Variable(tf.zeros([train_labels.shape[1]]))\n",
    "# inicializalas\n",
    "sess.run(tf.initialize_all_variables())\n",
    "# regresszio\n",
    "y=tf.nn.softmax(tf.matmul(x,W)+b)\n",
    "cross_entropy=tf.reduce_mean(-tf.reduce_sum(y_*tf.log(y),reduction_indices=[1]))\n",
    "train_step=tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "# tanitas: 1000 epoch, 50-es kotegek\n",
    "for i in range(1000):\n",
    "    batch=get_batch(50)\n",
    "    train_step.run(session=sess,feed_dict={x: batch[0], y_: batch[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy=tf.reduce_mean(tf.cast(tf.equal(tf.argmax(y,1),tf.argmax(y_,1)),tf.float32))\n",
    "print(\"Accuracy:\\t%g\"%accuracy.eval(session=sess,feed_dict={x: test_images, y_: test_labels}))\n",
    "y_pred=np.argmax(sess.run(y,feed_dict={x:test_images,y_:test_labels}),1)\n",
    "y_true=np.argmax(test_labels,1)\n",
    "print(\"Precision:\\t%g\"%precision_score(y_true,y_pred,average=\"macro\"))\n",
    "print(\"Recall score:\\t%g\"%recall_score(y_true,y_pred,average=\"macro\"))\n",
    "print(\"F1 score:\\t%g\"%f1_score(y_true,y_pred,average=\"macro\"))\n",
    "print(\"Konfuzios matrix:\")\n",
    "print(confusion_matrix(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Osztályozás konvolúciós hálóval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape=shape,stddev=0.1,name=\"weights\"))\n",
    "def bias_variable(shape):\n",
    "    return tf.Variable(tf.constant(value=0.1,shape=shape))\n",
    "def conv2d(x,W,name):\n",
    "    return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding=\"SAME\",name=name)\n",
    "def maxpool_2x2(x):\n",
    "    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"SAME\")\n",
    "\n",
    "# konvolucios reteg: 1 28x28-as bemenet, 32 5x5-os szuro, 2x2-es zero padding --> 32 28x28-as kimenet\n",
    "W_conv1=weight_variable([5,5,1,32])\n",
    "b_conv1=bias_variable([32])\n",
    "h_conv1=tf.nn.relu(conv2d(tf.reshape(x,[-1,28,28,1]),W_conv1,\"h_conv1\")+b_conv1)\n",
    "# maxpool reteg: 32 db 28x28 --> 32 db 14x14\n",
    "h_pool1=maxpool_2x2(h_conv1)\n",
    "# konvolucios reteg: 32 28x28-as bemenet, 64 5x5-os szuro, 2x2-es zero padding --> 64 28x28-as kimenet\n",
    "W_conv2=weight_variable([5,5,32,64])\n",
    "b_conv2=bias_variable([64])\n",
    "h_conv2=tf.nn.relu(conv2d(h_pool1,W_conv2,\"h_conv2\")+b_conv2)\n",
    "# maxpool reteg: 64 db 14x14 --> 64 db 7x7\n",
    "h_pool2=maxpool_2x2(h_conv2)\n",
    "# a maxpool reteget kilapitjuk, es raadjuk egy teljesen osszekotott retegre: 3136 --> 2014 (ReLU)\n",
    "W_fc1=weight_variable([7*7*64,1024])\n",
    "b_fc1=bias_variable([1024])\n",
    "h_fc1=tf.nn.relu(tf.matmul(tf.reshape(h_pool2,[-1,7*7*64]),W_fc1)+b_fc1)\n",
    "# dropout\n",
    "keep_prob=tf.placeholder(tf.float32)\n",
    "h_fc1_drop=tf.nn.dropout(h_fc1,keep_prob)\n",
    "# kimeneti reteg: 1024 --> 10 (softmax)\n",
    "W_fc2=weight_variable([1024,10])\n",
    "b_fc2=bias_variable([10])\n",
    "y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop,W_fc2)+b_fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cross_entropy=tf.reduce_mean(-tf.reduce_sum(y_*tf.log(y_conv),reduction_indices=[1]))\n",
    "train_step=tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction=tf.equal(tf.argmax(y_conv,1),tf.argmax(y_,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "sess.run(tf.initialize_all_variables())\n",
    "for i in range(1000):\n",
    "    batch=get_batch(50)\n",
    "    if (i+1)%100==0:\n",
    "        print(\"Step %d, accuracy is %g.\"%(i+1,\n",
    "                        accuracy.eval(session=sess,feed_dict={x:batch[0], y_:batch[1], keep_prob:1.0})))\n",
    "    train_step.run(session=sess,feed_dict={x:batch[0],y_:batch[1],keep_prob:0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred=np.empty(test_images.shape[0])\n",
    "for i in range(test_images.shape[0]): # egyszerre is ra lehetne adni, de ahhoz sok memoria kell\n",
    "    out=sess.run(y_conv,feed_dict={x:  np.atleast_2d(test_images[i]),\n",
    "                                   y_: np.atleast_2d(test_labels[i]), keep_prob: 1.0})\n",
    "    y_pred[i]=np.argmax(out,1)\n",
    "y_true=np.argmax(test_labels,1)\n",
    "print(\"Precision:\\t%g\"%precision_score(y_true,y_pred,average=\"macro\"))\n",
    "print(\"Recall score:\\t%g\"%recall_score(y_true,y_pred,average=\"macro\"))\n",
    "print(\"F1 score:\\t%g\"%f1_score(y_true,y_pred,average=\"macro\"))\n",
    "print(\"Konfuzios matrix:\")\n",
    "print(confusion_matrix(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A konvolúciós rétegek kimenetei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def showConvLayerOutputs(layer,inputdata):\n",
    "    units=layer.eval(session=sess,feed_dict={x:np.reshape(inputdata,[1,784],order='F'),keep_prob:1.0})\n",
    "    no_filters=units.shape[3]\n",
    "    plt.figure(figsize=(32,35))\n",
    "    for i in range(0,no_filters):\n",
    "        plt.subplot(math.ceil(no_filters/6.0),6,i+1)\n",
    "        plt.title(\"Filter \"+str(i))\n",
    "        plt.imshow(units[0,:,:,i],interpolation=\"none\",cmap=\"gray\")\n",
    "def showConvLayerWeights(w):\n",
    "    weights=w.eval(session=sess)\n",
    "    no_filters=weights.shape[3]\n",
    "    plt.figure(figsize=(32,35))\n",
    "    for i in range(0,no_filters):\n",
    "        plt.subplot(math.ceil(no_filters/6.0),6,i+1)\n",
    "        plt.title('Filter '+str(i))\n",
    "        plt.imshow(weights[:,:,0,i],interpolation=\"none\",cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testInput=test_images[6]\n",
    "plt.imshow(np.reshape(testInput,[28,28]),interpolation=\"nearest\",cmap=\"gray\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "showConvLayerOutputs(h_conv1,testInput)\n",
    "showConvLayerWeights(W_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "showConvLayerOutputs(h_conv2,testInput)\n",
    "showConvLayerWeights(W_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
